# Dependencies
```
Python 3.8.10
absl-py==2.1.0
anyio==4.5.2
appnope==0.1.4
argon2-cffi==23.1.0
argon2-cffi-bindings==21.2.0
arrow==1.3.0
asttokens==3.0.0
astunparse==1.6.3
async-lru==2.0.4
attrs==24.2.0
babel==2.16.0
backcall==0.2.0
beautifulsoup4==4.12.3
bleach==6.1.0
cachetools==5.5.0
certifi==2024.8.30
cffi==1.17.1
charset-normalizer==3.4.0
comm==0.2.2
contourpy==1.1.1
cycler==0.12.1
debugpy==1.8.9
decorator==5.1.1
defusedxml==0.7.1
exceptiongroup==1.2.2
executing==2.1.0
fastjsonschema==2.21.1
flatbuffers==24.3.25
fonttools==4.55.2
fqdn==1.5.1
gast==0.4.0
gensim==4.3.3
google-auth==2.36.0
google-auth-oauthlib==1.0.0
google-pasta==0.2.0
grpcio==1.68.1
h11==0.14.0
h5py==3.11.0
httpcore==1.0.7
httpx==0.28.1
idna==3.10
importlib-metadata==8.5.0
importlib-resources==6.4.5
ipykernel==6.29.5
ipython==8.12.3
isoduration==20.11.0
jedi==0.19.2
jinja2==3.1.4
joblib==1.4.2
json5==0.10.0
jsonpointer==3.0.0
jsonschema==4.23.0
jsonschema-specifications==2023.12.1
jupyter-client==8.6.3
jupyter-core==5.7.2
jupyter-events==0.10.0
jupyter-lsp==2.2.5
jupyter-server==2.14.2
jupyter-server-terminals==0.5.3
jupyterlab==4.3.2
jupyterlab-pygments==0.3.0
jupyterlab-server==2.27.3
keras==2.13.1
kiwisolver==1.4.7
libclang==18.1.1
Markdown==3.7
MarkupSafe==2.1.5
matplotlib==3.7.5
matplotlib-inline==0.1.7
mistune==3.0.2
nbclient==0.10.1
nbconvert==7.16.4
nbformat==5.10.4
nest-asyncio==1.6.0
notebook-shim==0.2.4
numpy==1.24.3
oauthlib==3.2.2
opt-einsum==3.4.0
overrides==7.7.0
packaging==24.2
pandas==2.0.3
pandocfilters==1.5.1
parso==0.8.4
pexpect==4.9.0
pickleshare==0.7.5
pillow==10.4.0
pkgutil-resolve-name==1.3.10
platformdirs==4.3.6
prometheus-client==0.21.1
prompt-toolkit==3.0.48
protobuf==4.25.5
psutil==6.1.0
ptyprocess==0.7.0
pure-eval==0.2.3
pyasn1==0.6.1
pyasn1-modules==0.4.1
pycparser==2.22
pygments==2.18.0
pyparsing==3.1.4
python-dateutil==2.9.0.post0
python-json-logger==2.0.7
pytz==2024.2
PyYAML==6.0.2
pyzmq==26.2.0
referencing==0.35.1
requests==2.32.3
requests-oauthlib==2.0.0
rfc3339-validator==0.1.4
rfc3986-validator==0.1.1
rpds-py==0.20.1
rsa==4.9
scikit-learn==1.3.2
scipy==1.10.1
Send2Trash==1.8.3
six==1.17.0
sklearn==0.0
smart-open==7.0.5
sniffio==1.3.1
soupsieve==2.6
stack-data==0.6.3
tensorboard==2.13.0
tensorboard-data-server==0.7.2
tensorflow==2.13.0
tensorflow-estimator==2.13.0
tensorflow-macos==2.13.0
termcolor==2.4.0
terminado==0.18.1
threadpoolctl==3.5.0
tinycss2==1.4.0
tomli==2.2.1
tornado==6.4.2
traitlets==5.14.3
types-python-dateutil==2.9.0.20241206
typing-extensions==4.5.0
tzdata==2024.2
Unidecode==1.3.8
uri-template==1.3.0
urllib3==2.2.3
wcwidth==0.2.13
webcolors==24.8.0
webencodings==0.5.1
websocket-client==1.8.0
werkzeug==3.0.6
wrapt==1.17.0
zipp==3.20.2
```

# Implementation Running
## Data Processing
Raw data is stored in ```data_raw```. The jupyter notebook ```convert.ipynb``` cleans the data and stores it in ```data_clean```.

## Models
The jupyter notebook ```models.ipynb``` can be run sequentially. Each section is well commented and labeled with which model each function corresponds to. There is no need to retrain the word2vec model. I've already trained it, and the model is stored in ```greek_word2vec.model```, which can be directly loaded from commented out code.

Additionally, the models for chunk sizes 25, 50, 100, and 200 with percentages 0.2 have already been trained, and the weights are stored in model_weights. My machine did not have the capacity to do more processing due to the lack of a GPU, but I fully encourage you to push the models to their extremes if you have access to more powerful servers. Thank you!